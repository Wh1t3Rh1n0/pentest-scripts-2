# pentest-scripts-2

*More miscellaneous, one-off and/or convenience scripts I created while red-teaming and pentesting.*

> This README is automatically generated by <code>generate-readme.sh</code>.

---

## merge-hashcat.py

```
merge-hashcat.py
----------------
Matches passwords cracked with hashcat to their usernames.

Usage: merge-hashcat.py <user:hash file> <hash:password file>

Notes: The "hash:password" file is created by hashcat's -o option.

       The "user:hash" file is easy to create using your original hashdump and
       the "cut" command. An example of creating this file from hashes dumped
       from a Windows domain controller follows:
       
       cat raw_dump.txt | cut -d ':' -f 1,4 > dumped-users_hashes.txt

```

## nessus-merger.py

```
nessus-merger.py (Originally 'merger.py', by mastahyeti)
================

Merge multiple .nessus files into a single file.

Usage
-----
1. Copy all .nessus files into a folder.
2. Run this script from within that folder.
3. Merged .nessus report will be saved as 'nss_report/report.nessus'.


Credits
-------
This script was created by mastahyeti, and the originals can be found here:
- https://gist.github.com/btoews/2720173
- https://tkit.dev/2011/07/09/merging-multiple-nessus-scans-python-script/

I only mirrored it and added this help text to give proper credit.

```

## trufflehog-json2csv.py

```
trufflehog-json2csv.py - by Wh1t3Rh1n0
----------------------

Converts TruffleHog JSON output to a CSV file.

Usage: ./trufflehog-json2csv.py <INPUT FILE> <OUTPUT FILE> [Excluded file extensions]

Example:

    ./trufflehog-json2csv.py trufflehog.json output.csv .dll .exe .png .jpg

TruffleHog command used to generate the JSON file referenced above:

    ./trufflehog filesystem --json $PWD/input-files/ | tee trufflehog.json

```

## analyze-user_pass.sh

```
Simple password analysis - user:password edition // by Wh1t3Rh1n0
================================================ //    2023-12-11

Takes a colon-separated list of usernames and passwords (e.g., Hashcat output)
and returns lists of users whose passwords matched certain criteria or
weaknesses.

The list of affected usernames (but NOT passwords) is returned as output, so
the list can be safely provided to customers without disclosing users'
passwords, and specific remediation actions can be taken.

Currently checks:
- Password length
- Passwords containing common keywords

Usage:
------
./analyze-user_pass.sh <user:password file> <output dir> [company name regex]

Note that the regex is optional and case insensitive.

Example:
--------
./analyze-user_pass.sh cracked.txt 'Password analysis' 'Dewey|Cheatem|Howe|DCH'

```

## extract-everything.sh

```
extract-everything.sh
=====================

Extracts all the archives stored in all subdirectories in an organized way.
Good for extracting bulk data before further analysis.

The process used for extraction is:

1. Find all the archive files in all subdirectories of the current directory.

2. For every archive that is found:

    i. Create a folder in the same location as the archive, named
       <ARCHIVE FILENAME>.extracted.

    ii. Extract all the contents of the archive into the created folder.

    iii. Delete the original archive.

Usage: From *inside* the target folder, call this script with the
       argument, "go".

Extra options: "go --keep" will keep the original archive instead of deleting
               it after extraction.

Example:    cd ./data/
            bash ../extract-everything.sh go --keep
```

## eyewitness-default-creds.sh

```
eyewitness-default-creds.sh
===========================

Extracts all default credentials from an EyeWitness report into a single list.
The list is printed to stdout. Call this script from *within* the EyeWitness
report folder.

Usage:

    cd <EyeWitness report folder>
    
    bash <Script path>/eyewitness-default-creds.sh | tee ../default-creds.txt

```

## generate-readme.sh

```
This script generates the README.md file for this repository.
```

## ipport-collect-raw-http.sh

```
ipport-collect-raw-http.sh
==========================

Retrieves HTTP/HTTPS (whichever works) headers and content from a webserver and
saves the output in a IP_PORT-named file inside the folder, 'output.raw-http'.

Useful for doing stuff like grabbing version numbers from the headers/body of
a lot of web servers all at once.

Usage: bash ipport-collect-raw-http.sh <IP:Port list> [Path]

If the optional path is specified, it will be used to request a specific URL
path during every request (e.g., "/README.html").

Example:

    bash ipport-collect-raw-http.sh webservers.txt
    cd output.raw-http
    grep -i '< server' *
```

## nessus-all_findings.sh

```
This script outputs ALL the findings from a Nessus CSV file into a slightly
more readable/greppable format.

Output is CSV with semicolons as field delimiters. Columns output are:

Severity ; Issue ; Protocol ; Host ; Port

Outputs to stdout.

Usage: ./nessus-all_findings.sh <NESSUS CSV FILE> > <OUTPUT FILE>

```

## nessus-csv2ip.sh

```
nessus-csv2ip.sh
----------------
Converts a Nessus exported CSV file to a colon-separated list of IPs and ports.

Outputs to stdout.

Usage: ./nessus-csv2ip.sh <CSV FILE> [--udp] > <OUTPUT FILE>

Requires: grep, awk, sort

The script displays TCP ports by default. Add the "--udp" option to output
UDP ports instead.

```

## s3-bucket-check.sh

```
s3-bucket-check.sh
------------------
A simple script to quickly test an Amazon AWS S3 bucket for read and
write access. If read access is allowed, the script automatically
attempts to download all contents of the S3 bucket.

Requires the awscli tools to be installed.

Note that the bucket name should be the bucket name only and not
include .s3.amazonaws.com.

Usage: bash ./s3-bucket-check.sh <BUCKET>

Example: bash ./s3-bucket-check.sh acmebucket

```

## search-all_findings.sh

```
search-all_findings.sh
======================
Search the CSV file output by 'nessus-all_findings.sh' for lines that match
the regex. Search is case insensitive.

Outputs are:
- STDERR: Raw search results, showing full matching lines.
- STDOUT: IP:Port formatted list of matching hosts, sorted and uniqued.

Optional arguments are:
--noports   : STDOUT outputs IP addresses only instead of IP:Port

Usage: search-all_findings.sh <CSV FILE> <REGEX SEARCH QUERY> [OPTIONS]

Example:

./search-all_findings.sh all_findings.csv 'smb signing' --noports > targets.txt
```

## sort-ipport.sh

```
sort-ipport.sh
==============

Sorts a list of colon-delimited IP addresses and port numbers.

To use, pipe your list into the execution of this script.

Example:

    cat ip_port_list.txt | bash sort-ipport.sh
```

## sort-ip.sh

```
sort-ip.sh
==========

Sorts a list of IP addresses.

To use, pipe your list into the execution of this script.

Example:

    cat ip_list.txt | bash sort-ip.sh
```

